<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>C++ 基础回顾</title>
    <url>/2023/06/21/CppBasic/</url>
    <content><![CDATA[
# 类和面向对象

## 静态成员

如果一个成员变量被声明为 `static`，则该类的所有对象均可以访问该变量。如果一个成员函数被声明为 `static`，则它可以在类的任何实例被定义之前调用。

**静态成员变量必须在类中声明，在类外部定义。**

## 友元

## 派生

### 构造与析构

派生类对象构造时，先调用基类的构造函数，再调用自身的构造函数。
派生类对象析构时，先调用自身的析构函数，再调用基类的析构函数。

```cpp
#include <iostream>

struct A {
    A() {
        std::cout << "Hello A" << std::endl;
    }
    ~A() {
        std::cout << "Bye A" << std::endl;
    }
};

struct B: public A{
    B() {
        std::cout << "Hello B" << std::endl;
    }
    ~B() {
        std::cout << "Bye B" << std::endl;
    }
};

int main() {
    A a;
    B b;
    return 0;
}
```

输出结果为

```
Hello A
Hello A
Hello B
Bye B
Bye A
Bye A
```

## 多态
]]></content>
      <tags>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title>STL 之容器</title>
    <url>/2023/06/22/Container-STL/</url>
    <content><![CDATA[
# vector

## 初始化

```cpp
#include <iostream>
#include <vector>
using namespace std;

int main()
{
    vector<int> vec;
    for (int i = 0; i < 10; i++)
        vec.push_back(i);     // 添加元素初始化
    vector<int>::iterator it; // 迭代器
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " "; // 输出
    cout << endl;
    vec.pop_back(); // 弹出最后一个元素
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " "; // 输出
    return 0;
}

// 0 1 2 3 4 5 6 7 8 9
// 0 1 2 3 4 5 6 7 8
```

## 大小、容量和遍历

```cpp
#include <iostream>
#include <vector>
using namespace std;

int main()
{
    vector<int> vec;
    for (int i = 0; i < 10; i++)
        vec.push_back(i); // 添加元素初始化
    if (vec.empty())
    {
        cout << "Vec is empty.\n";
    }
    else
    {
        cout << "Vec is not empty.\n";
    }

    vector<int>::iterator it; // 迭代器
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " "; // 遍历方式 1
    cout << endl;

    int sizeOfVec = vec.size();
    for (int i = 0; i < sizeOfVec; i++)
        cout << vec.at(i) << " ";
    cout << endl; // 遍历方式 2



    cout << "The size of vec: " << vec.size() << ";" << endl;
    cout << "The capacity of vec: " << vec.capacity() << ";" << endl;
    vec.resize(30);
    cout << "The size of vec: " << vec.size() << ";" << endl;
    cout << "The capacity of vec: " << vec.capacity() << ";" << endl;
    return 0;
}

// Vec is not empty.
// 0 1 2 3 4 5 6 7 8 9
// 0 1 2 3 4 5 6 7 8 9
// The size of vec: 10;
// The capacity of vec: 16;
// The size of vec: 30;
// The capacity of vec: 32;
```

## 使用算法和自定义函数

```cpp
#include <iostream>
#include <vector>
#include <algorithm>

using namespace std;

struct Student
{
    int id;
    int score;

    Student(int id, int score) : id(id), score(score) {}
};

void initialize(vector<Student> &vec, int num)
{
    while (num > 0)
    {
        Student temp(0, 0);
        temp.id = num;
        int i = rand() % 100;
        temp.score = (i >= 80) ? i : i % 40 + 60;
        vec.push_back(temp);
        num--;
    }
}

void print(Student &student)
{
    cout << "ID: " << student.id << ", Score: " << student.score << ";\n";
}

bool greater90(Student &student)
{
    if (student.score >= 90)
        return true;
    else
        return false;
}

int main()
{
    vector<Student> vec;
    initialize(vec, 10);
    for_each(vec.begin(), vec.end(), print); // 必须包含头文件 <algorithm>
    cout << "And there are " << count_if(vec.begin(), vec.end(), greater90) << " students' score over 90.\n";
    return 0;
}

// ID: 10, Score: 67;
// ID: 9, Score: 69;
// ID: 8, Score: 93;
// ID: 7, Score: 78;
// ID: 6, Score: 90;
// ID: 5, Score: 92;
// ID: 4, Score: 64;
// ID: 3, Score: 98;
// ID: 2, Score: 83;
// ID: 1, Score: 69;
// And there are 4 students' score over 90.
```

## 基本操作

```cpp
#include <iostream>
#include <vector>
#include <algorithm>

using namespace std;

bool greater6(const int &num)
{
    return num > 6;
}

int main()
{

    // 定义
    vector<int> vec;

    // 初始化
    for (int i = 1; i < 10; i++)
        vec.push_back(rand() % 100);

    // 访问
    vector<int>::iterator it;
    cout << "This is vec: ";
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;
    cout << vec.at(1) << endl;    // 访问元素
    cout << vec[3] << endl;       // 访问元素
    vec.at(vec.size() - 1) = 100; // 访问元素并更改
    cout << vec.front() << endl;  // 访问第一个元素
    cout << vec.back() << endl;   // 访问最后一个元素
    cout << *vec.begin() << " " << *vec.end() << " " << *vec.rbegin() << " " << *vec.rend() << endl;
    // 注意 find 的返回值
    cout << "100 is at the position of " << find(vec.begin(), vec.end(), 100) - vec.begin() << ".\n";
    cout << "No. " << find_if(vec.begin(), vec.end(), greater6) - vec.begin() << " element in vec is greater than 6.\n";

    // 排序
    cout << "Sort vec: ";
    std::sort(vec.begin(), vec.end());
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;

    // 插入
    vec.push_back(29);           // 插入到最后
    vec.insert(vec.begin(), 99); // 插入到最前面
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;
    vec.insert(vec.begin(), 2, 888); // 插入 2 个 888 到最前面，注意不是 888 个 2
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;

    // 删除
    vec.pop_back(); // 弹出最后一个元素
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;
    vec.erase(vec.begin()); // 删除第一个元素
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;
    vec.erase(vec.begin() + 3); // 删除第 4 个元素
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;
    vec.clear(); // 清空
    cout << "Clear: ";
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;

    // 交换
    vector<int> vec_swap;
    vec_swap.push_back(1);
    vec.swap(vec_swap);
    cout << "After swap: ";
    for (it = vec.begin(); it != vec.end(); it++)
        cout << *it << " ";
    cout << endl;

    return 0;
}

// This is vec: 7 49 73 58 30 72 44 78 23
// 49
// 58
// 7
// 100
// 7 0 100 0
// 100 is at the position of 8.
// No. 0 element in vec is greater than 6.
// Sort vec: 7 30 44 49 58 72 73 78 100
// 99 7 30 44 49 58 72 73 78 100 29
// 888 888 99 7 30 44 49 58 72 73 78 100 29
// 888 888 99 7 30 44 49 58 72 73 78 100
// 888 99 7 30 44 49 58 72 73 78 100
// 888 99 7 44 49 58 72 73 78 100
// Clear:
// After swap: 1
```

# list

## 定义

```cpp
#include <iostream>
#include <list>
#include <algorithm>

using namespace std;

int main()
{

    // 定义
    list<int> li;
    list<int> li1(4);                        // 定义并确定大小
    list<int> li2(6, 7);                     // 定义并初始化 6 个 7
    list<int> li3(li2);                      // 从别的 list 复制
    list<int> li4(li2.begin(), --li2.end()); // 从别的 list 复制若干元素
    list<int>::iterator it;
    cout << "li: ";
    for (it = li.begin(); it != li.end(); it++)
        cout << *it << " ";
    cout << endl;
    cout << "li1: ";
    for (it = li1.begin(); it != li1.end(); it++)
        cout << *it << " ";
    cout << endl;
    cout << "li2: ";
    for (it = li2.begin(); it != li2.end(); it++)
        cout << *it << " ";
    cout << endl;
    cout << "li3: ";
    for (it = li3.begin(); it != li3.end(); it++)
        cout << *it << " ";
    cout << endl;
    cout << "li4: ";
    for (it = li4.begin(); it != li4.end(); it++)
        cout << *it << " ";
    cout << endl;
    return 0;
}

// li:
// li1: 0 0 0 0
// li2: 7 7 7 7 7 7
// li3: 7 7 7 7 7 7
// li4: 7 7 7 7 7
```

## 基本操作

```cpp
#include <iostream>
#include <list>
#include <algorithm>

using namespace std;

int main()
{

    list<int> li(6, 9);

    list<int>::iterator it;
    cout << "Original: ";
    for (it = li.begin(); it != li.end(); it++)
        cout << *it << " ";
    cout << endl;

    // 添加和删除
    li.push_front(1);
    li.push_back(666);
    cout << "Add: ";
    for (it = li.begin(); it != li.end(); it++)
        cout << *it << " ";
    cout << endl;
    li.pop_back();
    li.pop_front();
    cout << "Remove: ";
    for (it = li.begin(); it != li.end(); it++)
        cout << *it << " ";
    cout << endl;

    // 大小和容量
    cout << "The size of li: " << li.size() << endl;
    cout << "The max size of li: " << li.max_size() << endl;
    li.resize(100);
    cout << "The size of li (after resize): " << li.size() << endl;

    // front and back
    li.resize(6);
    li.push_front(1);
    li.push_back(1000);
    cout << "front(): " << li.front() << endl;
    cout << "back(): " << li.back() << endl;

    // 修改
    li.reverse(); // 反序
    cout << "Reverse: ";
    for (it = li.begin(); it != li.end(); it++)
        cout << *it << " ";
    cout << endl;
    li.assign(4, 888); // 重新赋值
    cout << "Assign (li): ";
    for (it = li.begin(); it != li.end(); it++)
        cout << *it << " ";
    cout << endl;

    list<double> li2;
    list<double>::iterator it2;
    li2.assign(li.begin(), li.end()); // 用别的 lsit 重新赋值
    cout << "Assign (li2): ";
    cout.precision(2);
    for (it2 = li2.begin(); it2 != li2.end(); it2++)
        cout << std::fixed << *it2 << " ";
    cout << endl;

    return 0;
}

// Original: 9 9 9 9 9 9
// Add: 1 9 9 9 9 9 9 666
// Remove: 9 9 9 9 9 9
// The size of li: 6
// The max size of li: 768614336404564650
// The size of li (after resize): 100
// front(): 1
// back(): 1000
// Reverse: 1000 9 9 9 9 9 9 1
// Assign (li): 888 888 888 888
// Assign (li2): 888.00 888.00 888.00 888.00
```

```cpp
#include <iostream>
#include <list>
#include <algorithm>

using namespace std;

void printOne(const int &num)
{
    cout << num << " ";
}

void printAll(string name, list<int> &li)
{
    cout << name << ": ";
    for_each(li.begin(), li.end(), printOne);
    cout << endl;
}

int main()
{

    list<int> li;
    list<int> li2;

    for (int i = 0; i < 10; i++)
    {
        li.push_back(rand() % 100);
        li2.push_back(rand() % 100);
    }
    printAll("Original(li)", li);
    printAll("Original(li2)", li2);

    // insert()
    li.insert(li.begin(), 999);
    li.insert(li.end(), 3, 777);
    printAll("Insert(li)", li);
    list<int>::iterator it = li2.begin();
    it++;
    li2.insert(it, 3, 444);
    printAll("Insert(li2)", li2);
    li.insert(li.begin(), li2.begin(), li2.end());
    printAll("Insert(li)", li);

    // erase()
    li.erase(li.begin());
    printAll("Erase(li)", li);
    li.erase(li.begin(), li.end());
    printAll("Erase(li)", li);

    // clear()
    li2.clear();
    printAll("Clear(li2)", li2);

    return 0;
}

// Original(li): 7 73 30 44 23 40 92 87 27 40
// Original(li2): 49 58 72 78 9 65 42 3 29 12
// Insert(li): 999 7 73 30 44 23 40 92 87 27 40 777 777 777
// Insert(li2): 49 444 444 444 58 72 78 9 65 42 3 29 12
// Insert(li): 49 444 444 444 58 72 78 9 65 42 3 29 12 999 7 73 30 44 23 40 92 87 27 40 777 777 777
// Erase(li): 444 444 444 58 72 78 9 65 42 3 29 12 999 7 73 30 44 23 40 92 87 27 40 777 777 777
// Erase(li):
// Clear(li2):
```

```cpp
#include <iostream>
#include <list>
#include <algorithm>

using namespace std;

void print(int &li) {
    cout << li << " ";
}

int main() {
    list<int> li1, li2;
    for (int i = 10; i > 0; i--) {
        li1.push_back(rand() % 100);
        li2.push_back(rand() % 100);
    }
    //list<int>::iterator it;
    cout << "li1: " << endl;
    for_each(li1.begin(), li1.end(), print);
    cout << endl;
    cout << "li2: " << endl;
    for_each(li2.begin(), li2.end(), print);
    cout << endl;
    cout << "li1, sort(), default: " << endl;
    li1.sort();
    for_each(li1.begin(), li1.end(), print);
    cout << endl;
    cout << "li2, sort(), decrease: " << endl;
    li2.sort(greater<int>());//降序排列
    for_each(li2.begin(), li2.end(), print);
    cout << endl;
    cout << "merge li1 and li2: " << endl;
    li1.merge(li2);
    for_each(li1.begin(), li1.end(), print);
    cout << endl;
    cout << "after merge, li2: " << endl;
    for_each(li2.begin(), li2.end(), print);
    cout << "li2, add elements: " << endl;
    li2.push_back(999);
    li2.push_front(100);
    for_each(li2.begin(), li2.end(), print);
    cout << endl;
    cout << "li2, remove(): " << endl;
    li2.remove(999);
    for_each(li2.begin(), li2.end(), print);
    //li2.remove_if()
    return 0;
}
```

# deque

# set

# multiset

# map

# multimap
]]></content>
      <tags>
        <tag>Cpp</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title>基本数据结构 template</title>
    <url>/2023/06/22/Data-Structure/</url>
    <content><![CDATA[
# 线性表

## 顺序存储

```cpp
#include <iostream>

using namespace std;

#define MAX_SIZE 66

template<class T>
struct SqList {
    T data[MAX_SIZE];
    int length;
};

// 插入
template<class T>
bool ListInsert(SqList<T> &L, int i, T e) {
    // i 取值为 1 <= i <= length + 1
    if (i < 1 || i > L.length + 1) {
        return false;
    }
    if (i >= MAX_SIZE)
        return false;
    for (int j = L.length; j >= i; j--)
        L.data[j] = L.data[j - 1];
    L.data[i - 1] = e;
    L.length++;
    return true;
}

// 删除
template<class T>
bool ListDelete(SqList<T> &L, int i, T &e) {
    if (i < 1 || i > L.length)
        return false;
    e = L.data[i - 1];
    for (int j = i; j < L.length; j++)
        L.data[j - 1] = L.data[j];
    L.length--;
    return true;
}

// 查找
template<class T>
int LocateElem(const SqList<T> &L, T &e) {
    for (int i = 0; i < L.length; i++)
        if (L.data[i] == e)
            return i + 1;
    return 0;
}

// 遍历
template<class T>
void Print(const SqList<T> &L) {
    cout << "This is SqList: ";
    for (int i = 0; i < L.length; i++)
        cout << L.data[i] << " ";
    cout << endl;
}
```

## 链式存储

]]></content>
      <tags>
        <tag>Cpp</tag>
        <tag>Data-Structure</tag>
      </tags>
  </entry>
  <entry>
    <title>RouteNet-Fermi, Network Modeling with Graph Neural Networks</title>
    <url>/2024/03/14/RouteNet-Fermi/</url>
    <content><![CDATA[**Authors**

Miquel Ferriol-Galmés, Jordi Paillisse, José Suárez-Varela, Krzysztof Rusek, Shihan Xiao, Xiang Shi, Xiangle Cheng, Pere Barlet-Ros, Albert Cabellos-Aparicio

---

## Abstract

Network models are an essential block of modern networks. For example, they are widely used in network planning and optimization. However, as networks increase in scale and complexity, some models presents limitations, such as the assumption of Markovian traffic in queueing theory models, or the high computational cost of network simulators. Recent advances in machine learning, such as Graph Neural Networks(GNN), are enabling a new generation of network models that are data-driven and can learn complex non-linear behaviours. In this paper, we present RouteNet-Fermi, a custom GNN model that shares the same goal as queuing theory, while being considerably more accurate in the presence of realistic traffic models. The proposed model predicts accurately the delay, jitter, and packet loss of a network. We have tested RouteNet-Fermi in networks of increasing size (up to 300 nodes), including samples with mixed traffic profiles - e.g., with complex non-Markovian models - and arbitrary routing and queue scheduling configurations. Our experimental results show that RouteNet-Fermi achieves similar accuracy as computationally-expensive packet-level simulators and scales accurately to larger networks. Our model produces delay estimates with a mean relative error of 6.24% when applied to a test dataset of 1,000 examples, including network topologies one order of magnitude larger than those seen during training. Finally, we have also evaluated RouteNet-Fermi with measurements from a physical testbed and packet traces from a real-life network.

**Index terms:** Network Modeling, Graph Neural Networks, Queuing Theory

## Introduction

Network modeling is arguably one of the key tools when designing, building, and evaluating computer networks, even since the early days of networking. Network models are used in protocol design, performance evaluation, or network planning, just to cite a few examples. The two most widespread network modeling techniques are analytical models based on Queuing Theory (QT), and packet-level simulators.

However, the evolution of computer networks especially concerning complexity traffic characteristics, highlights some of the limitations of classical modeling techniques. Despite the tremendous success and widespread usage, some scenarios require more advanced techniques capable of accurately modeling complex traffic characteristics, while scaling to large real-world networks.

Especially, two relevant applications can benefit from advanced network modeling techniques: Network Digital Twins (NDT), and the network optimization tools. Commonly, an NDT is referred to as a virtual replica of a physical network that can accurately mimic its behavior and can make performance predictions for any given input condition (e.g., traffic, topology change, or new routing configuration). In other words, an NDT is an accurate network model that can support a wide range of network configurations and that can accurately model the complex non-linear behaviors behind real-world networks. As a result, NDTs can be used to produce accurate performance predictions, carry out what-if analysis, or perform network optimization by pairing it with an optimization algorithm.

In the context of network optimization, we can only optimize what we can model. Optimization algorithm operate by searching the network configuration space (e.g., to find an alternative routing scheme). For each configuration, a network model is used to estimate the resulting performance to see if it fulfills the optimization goal (e.g., minimize delay). To achieve efficient online optimization, it is essential to have an accurate and fast network model.

State-of-the-art modeling techniques have important limitations in effectively supporting the stringent requirements of current packet-switched networks. Queuing Theory imposes strong assumptions on the packet arrival process (Poisson traffic generation), which often is not sufficient to model real-world networks. Internet traffic has been extensively analyzed in the past two decades, and despite the community has not agreed on universal model, there is consensus that in general aggregated traffic shows strong auto-correlation and a heavy-tail.

Alternatively, packet-level simulators can accurately model networks. However, this comes at a high computational cost. The cost of a simulator depends linearly on the number of packets forwarded, which can be in the range of millions per second on a single 1Gbps link. In consequence, they are slow and impractical when considering large networks with realistic traffic volumes. This also severely limits its applicability to online network optimization, given the hard time constraints of such type of applications.

In this context, Deep Learning (DL) offers an extraordinary set of techniques to build accurate data-driven network models. DL models cam be trained with real data, without making any assumptions about physical networks. This enables building models with unprecedented accuracy by modeling the entire range of non-linear and multidimensional characteristics.

In this paper, we first make a systematic analysis of the performance of DL techniques for network modeling, using classical discrete-event network simulators as baseline. Specifically, we analyse the performance of Multilayer Perceptron-based (MLP), Recurrent Neural Network-based (RNN), and Graph Neural Network-based (GNN) models. We find that classical DL techniques, such as MLPs and RNNs are not practical enough for network modeling as they fail to provide accurate estimates when the network scenario differs from the examples seen during training (e.g., link failure). More recently, GNNs have been proposed as a novel neural network architecture specifically designed to learn over graph-structured data. They have been successfully used in other domains, such as quantum chemistry or logistics. However, in our analysis, we find that standard GNNs do not work well for network modeling and that we need a custom GNN architecture to model computer networks.

As a result, we propose RouteNet-Fermi (RouteNet-F), a GNN architecture for network modeling. RouteNet-F shares the same goals as Queuing Theory. It provides performance estimates (delay, jitter, and packet-loss) on given network scenarios (**Figure 1**) with remarkable accuracy and speed. The proposed model is not limited to Markovian traffic as Queuing Theory; it supports arbitrary models (including auto-correlated processes) which better represent the properties of real-world traffic. Interestingly, it also overcomes one of the main limitations of DL-based models: RouteNet-F generalises and provides accurate estimates in network scenarios not seen in training (e.g., different topologies, traffic metrics, routing configurations). We benchmark RouteNet-F against a state-of-the-art DL-based model (MimicNet) and with a state-of-the-art queuing theory model. We show that our model outperforms both baselines in all scenarios, achieving a 5.64% error when tested in a dataset with packet traces coming from a real-world network, an 11% error when evaluated in a physical testbed, and a 6.24% error when estimating the delay on networks over a large dataset with 1,000 network examples, with topologies ranging from 50 to 300 nodes.


![Black-box representation of RouteNet-F](Fig_1.png)
*Fig. 1 Black-box representation of RouteNet-F*

As any Deep Learning model, RouteNet-Fermi does not provide strong mathematical performance guarantees. However, the error of the estimates produced by the model is strongly bounded. The minimum estimated delay assumes no queuing across the path while the maximum assumes that all the queues are full. RouteNet-Fermi will not produce delay estimates outside these bounds.

The implementation of the model used in the evaluation in this paper is publicly available at [RouteNet-Fermi](https://github.com/BNN-UPC/Papers/wiki/RouteNet_Fermi).

## Challenges of Data-Driven Network Modeling

This section describes the main challenges that data-driven solutions need to address for network modeling. These challenges drove the core design of RouteNet-Fermi.

**Traffic Models:** Networks carry different types of traffic, so, supporting arbitrary stochastic traffic model is crucial. Experimental observations show that traffic on the Internet has strong auto-correlation and heavy-tails. In this context, it is well-known that main limitation of Queuing Theory is that it fails to provide accurate estimates on realistic Markovian models with continuous state space, or non-Markovian traffic models. The challenge for DL-based modeling is: How can we design a neural network architecture that can accurately model realistic traffic models.

**Training and Generalisation:** One of the main differences between analytical modeling (e.g., QT) and data-driven modeling is that the latter requires training. In DL, training involves obtaining a representative dataset of network measurements. The dataset needs to include a broad spectrum of network operational regimes, ranging from different congestion levels to various routing configurations, among others. In other words, the DL model cam predict only scenarios it has previously seen. Note that this is a common property of all neural network architectures.

Ideally, we would obtain this training dataset from a production network, since they commonly have systems in place to measure performance. However, it would be difficult to obtain a representative dataset. As we mentioned previously, we would need to measure the production network when it is experiencing extreme performance degradation as the result of link failures, incorrect configurations, severe congestion, etc. However, these situations are not common in production networks, which limits the ability to generate the training dataset. A reasonable alternative is creating these datasets in controlled testbeds, where it is possible to use different traffic models, implement a broad set of configurations, and replicate a wide range of network failures. Thus, the DL model can be trained on samples from testbed and then, applied to production networks. Hence, the research challenge is: how to design a DL model that can provide accurate estimates in network not seen during training? This incudes topologies, traffic, and configurations (e.g., queuing scheduling, routing) different from those seen in the training network testbed.

Leveraging a testbed that is smaller than a production network creates another challenge: the generalisation to larger networks. Real-world networks include hundreds or thousands of nodes, and building a network testbed at this scale is typically unfeasible. As a result, the Dl model should be able to learn from datasets with samples of small network testbeds and predict metrics for considerably larger networks, e.g., by a factor of 10-100x. Generalising to larger networks, or graphs in general, is currently an open research challenge in the field of GNNs.

**Quality of Service and Scheduling Policies:** A key requirement of modern networks is supporting Quality of Service (QoS), usually implemented via scheduling policies and mapping of traffic flows to QoS classes. Hence, a DL model should be able to predict the performance of the input traffic flows with their associated QoS class, similarly to how QT models support a wide range of scheduling policies.

## Limitations of Current Network Modeling Techniques

This section explores the performance of different DL models with respect to an accurate packet-level simulator and discusses the main limitations of existing network modeling techniques.

### A. Simulations as Network Modeling Technique

Network simulators reproduce the network behaviour at the granularity of packet events. This way, they can offer excellent accuracy and can be easily extended to include virtually and feature, such as packet scheduling, wireless networks, etc. Some simulators, such as Omnet++ or ns-3, are widely used and maintained.

However, their main limitation is the simulation time, especially for networks with high-speed links (10Gbps and above). Hence, depending on the amount of the traffic found in the target network, it may become unfeasible to simulate the network.

To illustrate this limitation, we simulate different topologies using the Omnet++ simulator to calculate the delay of a set of source-destination flows (CPU Intel Xeon Silver 4210R @2.40GHz). Network topologies are artificially generated using the Power-Law Out-Degree Algorithm from [this paper](https://ieeexplore.ieee.org/abstract/document/892042) and a traffic distribution that follows a Poisson process.

**Figure 2** shows the simulation time of such networks depending on the number of events. Here, an event refers to a transition in status of the network (e.g., adding a new packet to queue). We can see that the simulation time increases linearly and that simulating 4 billion events may appear a larger figure, consider that a 10Gbps link transmitting regular Ethernet frames translates to $\approx 820k$ events per seconds or 247 million events in 5 minutes of network activity for a single link. For example, in our experiments, the simulator takes around 8h to compute the performance metrics of a 300-node network.

![Simulation time depending on the number of processed events.](Fig_2.png)
*Fig. 2 Simulation time depending on the number of processed events.*

So, the main limitation of packet-level simulators is the simulation time. On the contrary, packet simulators offer unrivalled accuracy and can simulate virtually any scenario, from different routing configurations to replaying packet traces to simulate unknown traffic models. Because of this, hereafter, we consider the results from the simulator as the ground truth for the evaluations in this paper.

### B. Neural Networks as Network Modeling Techniques

The following sections review the performance of three common Neural Network (NN) architectures in the order of increasing complexity. First, we evaluate the Multilayer Perceptron, one of the simplest NNs. Next, Recurrent Neural Networks which are designed to work with sequences. Finally, we directly input the network into a Graph Neural Network specifically designed to work with graphs. The objective is to create a network model with the NN that can predict performance parameters for input networks with a wide range of characteristics. We are especially interested in the following parameters:

- **Accuracy:** How close is the prediction to simulation values?
- **Different Routing:** Does the accuracy degrade if we change the routing configuration?
- **Link Failures:** Quantify if link failures affect the quality of predictions?

We trained and test the three neural networks with the same dataset, obtained from simulations with Omnet++. The input values are the network characteristics (topology, routing configuration, traffic model and intensity, etc), and the output values are the delay for each path. Hence, all the errors are computed with respect to values of the simulator. We use four different datasets:

- **Traffic Models:** In it, we consider traffic models that are non-Poisson, auto-correlated, and with heavy tails. Table IV（此处表格应该不是 IV） details the different traffic models.
- **Same Routing:** Where the testing and training datasets contain networks with the same routing configurations.
- **Different Routing:** Where the training and testing datasets contain networks with different routing configurations.
- **Link failures:** Here, we iteratively remove one link of the topology to replicate a link failure, until we transform the network graph into a connected acyclic graph. This scenario is the most complex since a link failure triggers a change both in the routing and the topology.

To compare the different techniques, we compute the prediction error with respect to the accurate performance values produced by the simulator. Particularly we use the following error metrics:

- Mean Absolute Percentage Error (MAPE),
- Mean Squared Error (MSE),
- Mean Absolute Error (MAE), and
- Coefficient of Determination ($R^2$).

### C. Multilayer Perceptron

A Multilayer Perceptron (MLP) is a basic kind of NN from the family of feedforward NNs. In short, input data is propagated unidirectionally from the input neuron layer to the output layer. There may be an arbitrary number of hidden layers between these two layers, and this determines how deep is the NN.

- **Design:** Several works have leveraged an MLP to predict network performance metrics. Based on this work, we have built an MLP to predict the mean delay for each source-destination pair of nodes of a given network. The MLP has 8,280 inputs and two hidden layers with 4096 neurons and uses Rectified Linear Units (ReLU) as activation functions.
- **Evaluation:** Table I presents the error when predicting the network delay with respect to the results produced by the network simulator, including several traffic models. We can see that the MLP offers good accuracy for Poisson traffic, but the error increases significantly for the rest of the traffic models showing a MAPE between 23% and 84%.
  
Likewise, Table II shows the error of predicting the delay for the datasets with the same/different routing and link failures. We can see that the MLP cannot offer an accurate estimate when predicting the delay of a previously unseen routing configuration (1150% of error). This is due to the internal architecture of the MLP. During training, the MLP performs overfitting, meaning that the model only learns about the initial network topology used for training and not for any others. When we input a new topology, it does not have sufficient information to make an accurate prediction.

### D. Recurrent Neural Networks

Recurrent Neural Networks (RNN) are a more advanced type of NN. They have shown excellent performance when processing sequential data. This is mainly because they connect some layers to the previous ones, which gives them the ability to keep the state along sequences.  

- **Design:** Several works propose RNNs as a way to predict network performance. In this experiment, we build a sequential model with an RNN (Figure 4). Particularly, we choose a Gated Recurrent Unit (GRU). We initialise the state of each path with the sequence of nodes in the path and the features of the traffic model (e.g., packets, bandwidth, $\lambda$, $\epsilon$, $\alpha$, or on-off time), and we update the state of each link across the path. As an example, Figure 4 shows the structure of an RNN to model the sample network from Figure 3. We can see that the path of $flow_1$ is composed of $L_1$ and $L_3$. Once the path state has been computed, an MLP with 2 hidden layers computes the final output.
- **Evaluation:** We train the RNN with the same datasets as the previous subsection. Although the RNN supports better different traffic models than the MLP (Table I), it still struggles to produce accurate predictions when there are routing or topology changes (Table II), especially for different routing configurations (30% error), or when removing links (63%).

The reason behind the lack of capability of RNNs to understand routing changes and link failures is due to its internal architecture. RNNs can accommodate different end-to-end paths in the network (i.e., series of routers and links), thereby, making it easier to perform predictions for paths never seen in the training phase. However, this structure cannot store and update the status of individual links in the topology due to the inter-dependency between links and traffic flows (i.e., routing). In other words, if the status of a link changes, it affects several flows, and vice-versa. This generates circular dependencies that RNNs are not able to model (see more details in Sec. IV).

### E. Graph Neural Networks

Networks are fundamentally represented as graphs, where networking devices are the graph nodes and the links connecting devices are the graph edges. This interconnection translates to the fact that the **different elements in the network are dependent on each other**. Since most standard DL models (e.g., MLP, RNN) assume independent flow-level data points. This renders them inaccurate for our use case. Hence, a model that is capable of processing directly the network graph is arguably more desirable for network modeling, because **it will be able, not only to obtain information from the individual nodes and edges but also from the underlying data structure** (i.e., the relationships between the different elements).

GNNs are a type of neural network designed to work with graph-structured data. They have two key characteristics that make them a good candidate for a network model. First, GNNs have the ability to store node-level hidden states and update them in each iteration. Second, they process the input data directly as a graph, both during training and inference. This means that the internal structure of the neural network depends on the input graph. Hence, they can dynamically adapt to the underlying dependencies between the different elements of a network. The latter is of special importance, since changes in the network graph (e.g., routing modifications, link failures) are the main limitation of other DL-based models, such as MLPs and RNNs, as we have seen in the previous subsections.

In this section, we build a standard GNN model to predict the mean per-flow delay in networks.

**Design:** We implement a Message-Passing Neural Network (MPNN), a powerful state-of-the-art GNN architecture that can efficiently capture dependencies between the elements of input graphs. We define a graph $G$ described as a set of vertices (or nodes) $E$ and a set of edges (or links) $V$. Each node has a set of features $x_v$, and edges also have some features $e_{vw}$. The execution of an MPNN can be divided into three phases, an initialisation phase, a message-passing phase, and a readout phase. The first one defines a hidden state ($h_v^0$) using the node features ($x_v$). The second one is an iterative process that runs for $T$ time steps and that is defined by two functions: the message function $M_t$ and the update function $U_t$. During this phase, node hidden states ($h_v^t$), represented as fixed-size vectors, attempt to encode some meaningful information, and are iteratively updated by exchanging messages $m_v^{t+1}$ with their neighbours:

$$
m_v^{t+1} = \sum_{w \in N(v)}{M_t(h_v^t,h_w^t,e_{vw})}
$$
$$
h_v^{t+1} = U_t(h_v^t,m_v^{t+1})
$$

where $N(v)$ represents the neighbours of $v$ in graph $G$. Finally, the readout phase computes the output vector using a readout function $R$ that takes as input the final hidden states $h_v^T$:  

$$
\hat{y} = R(\{h_v^T | v \in G\})
$$

In our case, the input of the MPNN is the network topology graph. It performs $T$$=$$4$ message-passing iterations and the hidden state dimension is 32. The readout function is implemented with a two-layer fully connected NN with ReLUs as activation functions for the hidden layers and a linear activation for the output layer.

**Evaluation:** We evaluate the accuracy of the MPNN model when predicting the mean flow-level delay, as in previous subsections. Table III presents the delay prediction errors in the same scenarios of the previous experiments: routing configurations, both seen and not seen during training, and link failures. Unfortunately, the results are similar to those of the RNN: the routing configurations from the training dataset are easy to predict, with an error as low as 3%, while new routing configurations and link failures increase the error significantly (respectively, 50% and 125% of MAPE), thus showing even larger errors than the RNN model.  

The main reason behind the poor accuracy of the MPNN model is that the architecture of this model is directly built based on the network topology without taking into account the paths traversed by different traffic flows (i.e., the routing configuration), which is a fundamental property to understand inter-dependencies between flows and links. More specifically, when we test the model with the same routing configuration, it learns the relationships between flows and links. However, when we change this configuration, those previously-learned relationships are no longer valid, and the model is not able to capture the relationships between elements in the new scenario.

This intuition is better understood with an extreme packet loss example. Let’s suppose we have the sample network in Figure 3. The first flow ($Flow_1$) is transmitting at a rate of 2Gbps, and the second one ($Flow_2$) is transmitting at a rate of 0.5Gbps. As we can see, $L_1$ has a maximum capacity of 0.5Gbps. Because of this, $Flow_1$ will experience a large packet loss, which causes the traffic of $Flow_1$ at $L_3$ to be at most 0.5Gbps. Hence, instead of having 2Gbps+0.5Gbps of aggregated traffic at $L_3$, it will only have 1Gbps. Now, $Flow_2$, which initially could have experienced a lot of network congestion when going through the 2Gbps link will experience none as the state of the link changed.

Knowing this, we can see how there is a circular dependency between the flows and links found in the network. At the same time, the state of a flow depends on the state of the links they traverse, and the state of the links depends on the state of the flows passing through them.

If we apply a standard GNN over this example, the state of each flow is not updated at each hop. Therefore, the GNN does not have a structure that represents how the delay depends on both the links (topology) and the flows that go through each specific router.

Hence, we conclude that feeding the MPNN directly with the network topology graph is not sufficient to accurately perform network modeling. However, more complex and customised GNN-based architectures can still be powerful for modeling the inter-dependencies between the different network elements and generalising over new network scenarios by exploiting the underlying graph structure.
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>Network-Modeling</tag>
      </tags>
  </entry>
  <entry>
    <title>STL 之字符串</title>
    <url>/2023/06/21/String-STL/</url>
    <content><![CDATA[
# string

## 常用操作

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s1("Milo_Song_2120");
    char ch[] = "Hello_Cpp";
    string s2(s1);                       // 复制字符串
    string s3(s1, 2, 5);                 // 从 s1[2] 开始，复制 5 个字符
    string s4(ch, 4);                    // 复制 ch 的前 4 个字符
    string s5(9, '6');                   // 9 个字符 '6'
    string s6(s1.begin(), s1.end());     // 复制整个字符串
    string s7(s1.begin(), s1.end() - 1); // 复制除最后一个字符以外的所有字符
    cout << "s1 = " << s1 << ";" << endl;
    cout << "s2 = " << s2 << ";" << endl;
    cout << "s3 = " << s3 << ";" << endl;
    cout << "s4 = " << s4 << ";" << endl;
    cout << "s5 = " << s5 << ";" << endl;
    cout << "s6 = " << s6 << ";" << endl;
    cout << "s7 = " << s7 << ";" << endl;
    return 0;
}
```

输出结果为

```
s1 = Milo_Song_2120;
s2 = Milo_Song_2120;
s3 = lo_So;
s4 = Hell;
s5 = 666666666;
s6 = Milo_Song_2120;
s7 = Milo_Song_212;
```

## string 的大小和容量

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s("hello");
    cout << "Size of s: " << s.size() << endl;
    cout << "Length of s: " << s.length() << endl;
    cout << "Max size of s: " << s.max_size() << endl;
    cout << "Capacity of s: " << s.capacity() << endl;
    s.reserve(66);
    cout << "Capacity of s: " << s.capacity() << endl;
    return 0;
}
```

输出结果为

```
Size of s: 5
Length of s: 5
Max size of s: 9223372036854775791
Capacity of s: 22
Capacity of s: 79
```

⚠️ `s.reserve()` 和 `s.capacity()` 这两个函数没搞太懂。

## string 读取

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s("Hello_Song");
    cout << s.at(4) << endl;
    cout << s.at(s.length() - 1) << endl;
    cout << s[s.length()] << endl;
    cout << s[s.length() - 1] << endl;
    return 0;
}
```

输出结果为

```
o
g
 
g
```

## string 比较

`compare()` 函数

- `string1.compare(pos, n, string2)`
- 比较结果相同，返回 0 值
- 比较结果不同
  - `string1` 的字典序先于 `string2`，返回负值
  - 否则，返回正值

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s1("abcdef");
    string s2("hijkl");
    string s3("abcdef");
    string s4("abcd");
    cout << s1.compare(s2) << endl;
    cout << s1.compare(s3) << endl;
    cout << s1.compare(s4) << endl;
    cout << s1.compare(0, 4, s4);   //s1 -> abcd 与 s4 比较
    return 0;
}
```

输出结果为

```
-7
0
1
0
```

当然也可以直接使用比较运算符来比较。

## string 修改和替换

`assign()` 和 `swap()` 函数可以正常使用，但是 `erase()` 函数出现问题。

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s1("ABCDEFG");
    string s2, s3, s4, s5;
    s2.assign(s1);
    cout << s2 << endl;
    s3.assign(s1, 1, 3);
    cout << s3 << endl;
    s4.assign(6, 'X');
    cout << s4 << endl;
    s5.swap(s1);
    cout << s5 << endl;
    return 0;
}

// ABCDEFG
// BCD
// XXXXXX
// ABCDEFG
```

`insert()` 函数的使用如下。

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s1("ABCDEFG");
    string s2("_Bonjour_");
    s1.insert(1, s2); // 在 s1 的位置 1 插入 s2
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.insert(2, s2, 3); // 在 s1 的位置 2 插入 s2 位置 3 之后的所有字符
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.insert(2, s2, 3, 3);
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.insert(0, 5, '6');
    cout << s1 << endl;
    return 0;
}

// A_Bonjour_BCDEFG
// ABnjour_CDEFG
// ABnjoCDEFG
// 66666ABCDEFG
```

`append()` 函数的使用如下。

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s1("ABCDEFG");
    string s2("123456");
    s1.append(s2);
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.append(s2, 3);
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.append(s2, 3, 2);
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.append(6, '6');
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.append(s2.begin(), s2.end());
    cout << s1 << endl;
    return 0;
}

// ABCDEFG_Bonjour_
// ABCDEFGnjour_
// ABCDEFGnj
// ABCDEFG666666
// ABCDEFG_Bonjour_
```

`replace()` 函数的使用如下。

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s1("ABCDEFG");
    string s2("1234567");
    s1.replace(2, 3, s2); // 使用 s2 替代自 s1 位置 2 开始的 3 个字符
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.replace(2, 3, s2, 1, 4); // 使用 s2 的子串 '234' 替代自 s1 位置 2 开始的 3 个字符
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.replace(2, 3, 6, '6');
    cout << s1 << endl;
    s1 = "ABCDEFG";
    s1.replace(s1.begin(), s1.end(), s2);
    cout << s1 << endl;
    return 0;
}

// AB1234567FG
// AB2345FG
// AB666666FG
// 1234567
```

## string 输入

`getline()` 函数可以输入整行。

```cpp
string s1;
getline(cin, s1);
// 下面这个与上面的相同作用
getline(cin, s1, '\n');
// 下面这个以空格作为结束标志，例如输入 'ssss sss'，实际只能得到 'ssss'
getline(cin, s1, ' ');
```

## string 查找

```cpp
#include <iostream>
#include <string>
using namespace std;

int main()
{
    string s1("Hello, nice to meet you.");
    string alphabet("abcdefghijklmnopqrstuvwxyz");
    cout << s1.find('o') << endl;
    cout << s1.find('o', 9) << endl; // 从位置 9 开始 find
    cout << s1.find("nice") << endl;
    cout << s1.find("nihao", 0, 2) << endl; // 在 s1（从位置 0 开始）中查找 "nihao" 的前两个字符
    cout << s1.find_first_of(alphabet) << endl;
    cout << s1.find_last_of(alphabet) << endl;
    cout << s1.find_first_not_of(alphabet) << endl;
    cout << s1.find_last_not_of(alphabet) << endl;
    return 0;
}

// 4
// 13
// 7
// 7
// 1
// 22
// 0
// 23
```
]]></content>
      <tags>
        <tag>Cpp</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title>关于我自己</title>
    <url>/2023/06/06/about-CN/</url>
    <content><![CDATA[
简体中文 | [繁體中文](../about-TCN/index.html) | [English](../about/index.html) | [Français](../about-FR/index.html)

![Programming is art.](code.png)

# 你好！

欢迎访问我的个人主页，我也非常荣幸能够同你这样有趣的灵魂在此相遇。

# 学习经历

- 2017 - 2020，高中，安徽省亳州市第一中学
- 2020 - 至今，本科，吉林大学计算机科学与技术学院

# 参与项目

- RISC-V 指令集软件仿真
- 基于 YOLOv5 的智能捡拾机器人
- 我自己的 Repositories
  - [Heartbeat](https://github.com/created4u/heartbeat.git)
  - [Coursea](https://github.com/created4u/Coursea.git)

# 所获荣誉

（截止至 2023 年 8 月）

- 2020 - 2021，吉林大学三等奖学金
- 2021 - 2022，吉林大学二等奖学金
- 2021 - 2022，吉林大学计算机科学与技术学院院优秀学生
- 2023，[全国大学生物联网设计竞赛](http://iot.sjtu.edu.cn/Default.aspx)，东北赛区一等奖，全国总决赛二等奖

# 个人能力

- 英语水平良好，四六级均以优秀成绩通过，正在备考 TOEFL，能够流畅地阅读外文文献。
- 熟悉 C，C++，Java，Python，Kotlin，Swift，Go 等编程语言，有良好的编程能力。
- 熟悉 HTML，CSS，JavaScript，Node.js，Vue，Bootstrap 等技术，能够独立搭建网页。
- 有一定的开发经验，能够独立开发 iOS/iPadOS/macOS 和 Android 应用程序。
- 广泛接触软硬件，基础较为扎实，熟悉嵌入式开发。

# 兴趣爱好

- 语言学习。空余时间会学习各种有趣的语言，例如 Français，Русский，Español 等语言。
- 绘画（约等于～乱画）。没有系统地学过相关知识，就是想画啥画啥。
- 阅读文学。[Kafka](https://en.wikipedia.org/wiki/Franz_Kafka) 和 [Woolf](https://en.wikipedia.org/wiki/Virginia_Woolf) 是我最喜欢的作家之一，虽然有时候看不太懂，但是更让我痴迷不已。
- 设计各种有意思的东西，执着于用平凡的材料创造出不平凡的事物，用颜色表达情感。
- 摄影。用相机记录下每一个值得回忆的瞬间。

## 我的小作品 :)

这是几年前我画的第一幅画。

![The first man I drew.](him.PNG)

这是我家仙人掌开的花。

![Cactus flower.](cactus.jpeg)
]]></content>
      <categories>
        <category>-[about]</category>
      </categories>
  </entry>
  <entry>
    <title>Présentation de soi.</title>
    <url>/2023/06/06/about-FR/</url>
    <content><![CDATA[
Français | [English](../about/index.html) | [繁體中文](../about-TCN/index.html) | [简体中文](../about-CN/index.html)

![Programming is art.](code.png)

# Bonjour!

Bienvenue sur ma page d'accueil personnelle, et je suis heureux de rencontrer une âme aussi intéressante que vous.

# Expérience

- 2017 - 2020, Premier Lycée de Bozhou, Province d'Anhui
- 2020 - 2024, Collège d'informatique et de technologie, Université de Jilin

# Projets

- Émulateur basé sur RISC-V
- Robot de prélèvement intelligent utilisant YOLOv5
- Certains Github Repositories
  - [Heartbeat](https://github.com/created4u/heartbeat.git)
  - [Coursea](https://github.com/created4u/Coursea.git)

# Récompenses et Honneurs

(Mise à jour le 29, Août, 2023)

- 2020 - 2021, Bourse de deuxième classe, Université de Jilin
- 2021 - 2022, Bourse de troisième classe, Université de Jilin
- 2021 - 2022, Excellent étudiant universitaire, Université de Jilin
- 2023, [Concours national de conception IoT](http://iot.sjtu.edu.cn/Default.aspx), Premier Prix de la Région Nord-Est, Deuxième Prix de la Finale Nationale

# Compétence

- Bon niveau d'anglais, avoir réussi les CET-4 et CET-6 avec d'excellentes notes et savoir lire couramment la littérature étrangère.
- Familier avec C, C++, Java, Python, Kotlin, Swift, Go et d'autres langages de programmation, avec une bonne capacité de programmation.
- Familier avec HTML, CSS, JavaScript, Node.js, Vue, Bootstrap et d'autres technologies, capable de créer de manière indépendante des pages Web.
- Capable de développer de manière indépendante des applications iOS/iPadOS/macOS et Android.
- Etude approfondie des logiciels et du matériel, familiarisé avec le développement embarqué.

# Loisirs

- Apprendre des langues. Quand je suis libre, apprendre différentes langues est une merveilleuse façon de gagner du temps, Français, Русский, Español... ce sont mes préférées.
- Peinture. Juste pour le fun :P.
- En lisant. [Kafka](https://en.wikipedia.org/wiki/Franz_Kafka) et [Woolf](https://en.wikipedia.org/wiki/Virginia_Woolf) sont parmi mes auteurs préférés. Bien que parfois je ne comprenne pas entièrement leur travail brillant, cela me rend encore plus captivé.
- Concevez toutes sortes de choses intéressantes, insistez pour créer des choses extraordinaires avec des matériaux ordinaires et exprimez des émotions avec des couleurs.
- La photographie. Enregistrement de chaque instant de la vie normale avec caméra.

## Ma Création :)

Voici la première œuvre que j'ai peinte il y a plusieurs années.

![The first man I drew.](him.PNG)

Et c'est une fleur de cactus chez moi.

![Cactus flower.](cactus.jpeg)
]]></content>
      <categories>
        <category>-[about]</category>
      </categories>
  </entry>
  <entry>
    <title>關於我自己</title>
    <url>/2023/06/06/about-TCN/</url>
    <content><![CDATA[
繁體中文 | [简体中文](../about-CN/index.html) | [English](../about/index.html) | [Français](../about-FR/index.html)

![Programming is art.](code.png)

# 你好！

歡迎訪問我嘅個人主頁，我都非常榮幸能夠同你咁有趣嘅靈魂在此相遇。

# 學習經歷

- 2017 - 2020，高中，安徽省亳州市第一中學
- 2020 - 至今，本科，吉林大學計算機科學與技術學院

# 參與項目

- RISC-V 指令集軟件仿真
- 基於 YOLOv5 嘅智能撿拾機械人
- 我自己嘅 Repositories
  - [Heartbeat](https://github.com/created4u/heartbeat.git)
  - [Coursea](https://github.com/created4u/Coursea.git)

# 所獲榮譽

（截止至 2023 年 8 月）

- 2020 - 2021，吉林大學三等獎學金
- 2021 - 2022，吉林大學二等獎學金
- 2021 - 2022，吉林大學計算機科學與技術學院院優秀學生
- 2023，[全國大學生物聯網設計競賽](http://iot.sjtu.edu.cn/Default.aspx)，東北賽區一等獎，全國總決賽二等獎

# 個人能力

- 英語水平良好，四六級均以優秀成績通過，正在備考 TOEFL，能夠流暢地閱讀外文文獻。
- 熟悉 C，C++，Java，Python，Kotlin，Swift，Go 等編程語言，有良好的編程能力。
- 熟悉 HTML，CSS，JavaScript，Node.js，Vue，Bootstrap 等技術，能夠獨立搭建網頁。
- 有一定的開發經驗，能夠獨立開發 iOS/iPadOS/macOS 和 Android 應用程序。
- 廣泛接觸軟硬件，基礎較為紮實，熟悉嵌入式開發。

# 興趣愛好

- 語言學習。空餘時間會學習各種有趣嘅語言，例如 Français，Русский，Español 等語言。
- 繪畫（約等於~亂畫）。冇系統咁學過相關知識，就係想畫啥畫啥。
- 閱讀文學。[Kafka](https://en.wikipedia.org/wiki/Franz_Kafka) 同 [Woolf](https://en.wikipedia.org/wiki/Virginia_Woolf) 係我最鍾意嘅作家之一，雖然有時候睇唔係幾明，但係更令我癡迷不已。
- 設計各種有意思嘅嘢，執著于用平凡嘅材料創造出不平凡嘅嘢，用顏色表達情感。
- 攝影。用相機記錄的每一個值得回憶嘅瞬間。

## 個人作品 :)

係幾年前我畫嘅第一幅畫。

![The first man I drew.](him.PNG)
係我屋企仙人掌開嘅花。

![Cactus flower.](cactus.jpeg)
]]></content>
      <categories>
        <category>-[about]</category>
      </categories>
  </entry>
  <entry>
    <title>About Me</title>
    <url>/2023/06/06/about/</url>
    <content><![CDATA[
English | [繁體中文](../about-TCN/index.html) | [简体中文](../about-CN/index.html) | [Français](../about-FR/index.html)

![Programming is art.](code.png)

# Hello!

Welcome to my personal homepage, and I'm glad to meet such an interesting soul as you.

# Experience

- 2017 - 2020, No.1 High School of Bozhou, Anhui Province
- 2020 - 2024, College of Computer Science and Technology, Jilin University

# Projects

- Emulator based on RISC-V
- Intelligent picking robot using YOLOv5
- Some repositories
  - [Heartbeat](https://github.com/created4u/heartbeat.git)
  - [Coursea](https://github.com/created4u/Coursea.git)

# Awards

(Updated on 29, August, 2023)

- 2020 - 2021, Second Class Scholarship, Jilin University
- 2021 - 2022, Third Class Scholarship, Jilin University
- 2021 - 2022, College Excellent Student, Jilin University
- 2023, [National IoT Design Competition](http://iot.sjtu.edu.cn/Default.aspx), First Prize of Northeast Region, Second Prize of National Finals

# Competence

- Good level of English, passed CET-4 and CET-6 with excellent grades, and can read foreign literature fluently.
- Familiar with C, C++, Java, Python, Kotlin, Swift, Go and other programming languages, with good programming ability.
- Familiar with HTML, CSS, JavaScript, Node.js, Vue, Bootstrap and other technologies, able to independently build web pages.
- Able to independently develop iOS/iPadOS/macOS and Android applications.
- Extensive study of software and hardware, familiar with embedded development.

# Hobbies

- Learning languages. When I'm free, learning different languages is a wonderful way to consume time, Français, Русский, Español... those are my favorites.
- Painting. Just for fun :P.
- Reading. [Kafka](https://en.wikipedia.org/wiki/Franz_Kafka) and [Woolf](https://en.wikipedia.org/wiki/Virginia_Woolf) are among my favorite authors. Although sometimes I don't fully understand their brilliant work, it makes me even more engrossed.
- Design all kinds of interesting things, insist on creating extraordinary things with ordinary materials, and express emotions with colors.
- Photography. Recording every moment of normal life with camera.

## My Works :)

Here is the first work I painted several years ago.

{% asset_img him.PNG The first man I drew. %}

And this is a flower of cactus in my home.

![Cactus flower.](cactus.jpeg)
]]></content>
      <categories>
        <category>-[about]</category>
      </categories>
  </entry>
  <entry>
    <title>Ad hoc 网络路由协议</title>
    <url>/2023/06/24/ad-hoc-route-protocol/</url>
    <content><![CDATA[
# 分类

自组路由协议

- 扁平路由
  - 先验式（由表驱动），路由与交通模式无关，包括普通的路由和距离向量路由
    - FSR
    - FSLS
    - OLSR
    - TBRPF
  - 反应式（按需模式），需要时才保持路由状态
    - **AODV**
    - **DSR**
- 分级路由，在平面网络中引入层次概念
  - HSR
  - CGSR
  - ZRP
  - LANMAR
- 地理位置协助路由
  - GPSR
  - GeoCast
  - LAR
  - DREAM

# Flooding

洪泛路由算法（Flood Routing Algorithm）是一种简单而有效的网络路由算法，它用于在没有中央控制的网络中，将数据包从源节点传递到目标节点。该算法的基本原理是在网络中的每个节点接收到数据包后，将数据包向除了发送节点之外的所有相邻节点进行转发，以便数据包能够通过网络传播，直到到达目标节点。

以下是洪泛路由算法的详细介绍：

1. 初始化：在网络中，每个节点都维护一个路由表，记录了与其相邻的节点信息。开始时，每个节点只知道它直接相连的邻居节点。

2. 发送数据包：当一个节点要发送数据包到目标节点时，它首先检查自己的路由表，找到一个相邻节点作为下一跳，将数据包发送给该节点。

3. 数据包接收和处理：当一个节点接收到数据包时，它**首先检查数据包的目标地址**。如果目标地址是自己，那么该节点就完成了数据包的传递。否则，该节点会检查数据包的源地址，并在路由表中查找下一跳节点。

4. 数据包转发：节点在确定了下一跳节点后，将数据包复制并发送给除了源节点和下一跳节点之外的所有相邻节点。这样，数据包就会在网络中以广播的方式传播。

5. 循环检测：为了防止数据包在网络中无限循环，每个节点都需要维护一个已经接收过的数据包列表。当节点接收到一个数据包时，它会检查列表中是否已经存在相同的数据包。如果是，则丢弃该数据包，以避免循环。

6. 目标节点的确认：当数据包到达目标节点时，目标节点可以通过特定的方式向源节点发送确认消息，通知源节点数据包已经成功到达。

尽管洪泛路由算法具有简单和容错性的优点，但也存在一些问题。其中一个主要问题是网络中的节点数量增加时，数据包的传递路径变得非常复杂，导致网络拥塞和资源浪费。为了解决这个问题，现实世界中的网络通常采用更复杂的路由算法，如距离矢量路由算法（Distance Vector Routing）和链路状态路由算法（Link State Routing），以提高网络效率和性能。

# DSR

DSR（Dynamic Source Routing）路由协议是一种无线自组织网络中的路由协议，适用于移动自组织网络（MANETs）和无线传感器网络（WSNs）。DSR 协议的主要特点是源节点动态地确定数据包的路由路径，而不依赖于中央控制或固定的路由表。

1. 节点地址

   - 每个节点在网络中都有唯一的地址标识。

2. 路由发现

   - 源节点在发送数据包之前不知道数据包的完整路由路径。
   - 当源节点要发送数据包时，它首先检查自己的路由缓存。如果有目标地址的缓存记录，它可以直接使用该路由。
   - 如果没有缓存记录，源节点将发送一条路由请求（Route Request）消息广播到整个网络中。

3. 路由维护

   - 当其他节点收到路由请求消息时，如果发现自己是目标节点或者拥有目标节点的缓存路由记录，它将向源节点发送路由回复（Route Reply）消息，其中包含完整的路由路径信息。
   - 源节点接收到路由回复消息后，它就可以构建出数据包的完整路由路径，并将数据包发送到下一跳节点。
   - 中间节点收到数据包后，根据数据包中的路由信息将其转发给下一跳节点，直到数据包到达目标节点。

4. 路由维护和更新

   - 在数据包传递过程中，每个节点都会维护已经接收到的路由路径，以便在需要时进行路由回复。
   - 如果某个节点发现路由路径发生了变化（如节点移动或网络拓扑改变），它将发送路由错误（Route Error）消息通知网络中的其他节点，以便更新路由表和缓存记录。

5. 优点

   - DSR 协议适用于无线自组织网络，特别是移动自组织网络和无线传感器网络，具有很好的适应性和灵活性。
   - 由于路由路径是在数据包传递时动态确定的，因此可以避免中心化的路由控制和静态的路由表维护。
   - DSR 协议支持多路径路由，可以提高网络的容错性和可靠性。

6. 缺点

   - DSR 协议需要较大的路由请求和回复消息开销，特别是在网络规模较大时。
   - 节点移动频繁或网络拓扑变化剧烈时，路由发现和维护过程可能会引起较高的网络开销和延迟。
   - DSR 协议没有考虑到网络的负载情况和流量控制，可能导致网络拥塞和资源浪费。

总体而言，DSR 路由协议是一种灵活而适应性强的无线自组织网络路由协议，通过动态地确定数据包的路由路径，实现了移动自组织网络中的数据传输和路由发现。然而，在实际应用中，需要综合考虑网络规模、节点移动性、开销和延迟等因素，选择合适的路由协议以满足具体的需求。

# AODV

AODV（Ad hoc On-Demand Distance Vector）路由协议是一种无线自组织网络中的距离向量路由协议，适用于移动自组织网络（MANETs）和无线传感器网络（WSNs）。AODV 协议的设计目标是提供一种有效的路由选择机制，以适应节点的移动性和动态网络拓扑。

1. 节点地址

   - 每个节点在网络中都有唯一的地址标识。

2. 路由发现和维护

   - 源节点在发送数据包之前不知道数据包的完整路由路径。
   - 当源节点要发送数据包时，它首先检查自己的路由缓存。如果有目标地址的缓存记录，它可以直接使用该路由。
   - 如果没有缓存记录，源节点将发送一条路由请求（Route Request）消息广播到整个网络中。

3. 路由请求和回复

   - 中间节点收到路由请求消息后，会检查自己的路由表并决定是否能够到达目标节点。
   - 如果中间节点具有到目标节点的有效路由，它将向源节点发送路由回复（Route Reply）消息，其中包含完整的路由路径信息。
   - 如果中间节点无法到达目标节点，它将转发路由请求消息，以便其他节点能够响应。

4. 路由表维护

   - 每个节点都维护一个路由表，记录了到达其他节点的下一跳节点和跳数等信息。
   - 当节点接收到路由回复消息后，它将更新自己的路由表，并缓存该路由以备将来使用。
   - 路由表中的路由项会根据节点的移动性和网络拓扑的变化而进行动态更新。

5. 路由错误处理

   - 当节点发现某个路由不再可用（如节点移动或链路中断），它将发送路由错误（Route Error）消息通知网络中的其他节点。
   - 收到路由错误消息的节点会更新自己的路由表，删除无效的路由路径。

6. 优点

   - AODV 协议是一种基于需求的路由协议，只在需要时才发起路由请求，减少了网络开销和延迟。
   - AODV 协议支持适应节点的移动性和动态网络拓扑，能够及时更新路由表并适应变化的网络环境。
   - AODV 协议具有较好的扩展性，适用于中小规模的无线自组织网络。

7. 缺点

   - AODV 协议在高度移动的网络中可能会产生较高的路由维护开销，尤其是在大规模网络中。
   - AODV 协议没有考虑到网络的负载情况和流量控制，可能导致网络拥塞和资源浪费。

总体而言，AODV 路由协议是一种有效的无线自组织网络路由协议，通过根据需求发起路由请求并动态维护路由表，实现了移动自组织网络中的数据传输和路由发现。然而，在实际应用中，需要综合考虑网络规模、节点移动性、开销和延迟等因素，选择合适的路由协议以满足具体的需求。

# LAR

]]></content>
      <tags>
        <tag>Wireless-Network</tag>
      </tags>
  </entry>
  <entry>
    <title>粵語發音</title>
    <url>/2024/03/25/cantonese-1/</url>
    <content><![CDATA[> 注：以下教程是對[「粵語拼音速遞」（香港中文大學自學中心）](https://www.ilc.cuhk.edu.hk/workshop/Chinese/Cantonese/Romanization/)的總結。

---

## 聲母

![聲母](聲母.png)

### 與普通話相似的發音

b、p、m、f、d、t、n、l、g、k、w 的發音與普通話大致相同。

### z、c、s

粵語 z、c、s 的發音介乎普通話 z、c、s 和 j、q、x 之間。

### j

粵語中的 j 是半元音，相當於普通話的 y。

### 稍難的發音

| 聲母  | 示意圖                                                                                                                              | 發音方式                                                                  |
| --- | -------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |
| h   | ![h 發音方法](https://www.ilc.cuhk.edu.hk/workshop/Chinese/Cantonese/Romanization/ch2_initials/img/advanced/pronunce_h.png "h 發音方法") | 普通話的h是舌根音，而粵語是喉音。這個音對氣流形成阻力的位置在喉部，像英文的h。                              |
| ng  | ![](https://www.ilc.cuhk.edu.hk/workshop/Chinese/Cantonese/Romanization/ch2_initials/img/advanced/pronunce_ng.png)               | 普通話沒有ng聲母，而在粵語中這個音既可做聲母，也能單獨作韻母。粵語ng聲母叫做舌根鼻音，舌頭的位置跟發g、k一樣，只是把它發成鼻音即可。 |
| gw  | ![](https://www.ilc.cuhk.edu.hk/workshop/Chinese/Cantonese/Romanization/ch2_initials/img/advanced/pronunce_gw.png)               | 粵語聲母gw這個音叫做圓唇音舌根音。發這個音的舌位與發g相同，只不過把嘴唇收圓，近似發普通話 "瓜gua" 裏 "gu" 的部分。     |
| kw  | ![](https://www.ilc.cuhk.edu.hk/workshop/Chinese/Cantonese/Romanization/ch2_initials/img/advanced/pronunce_kw.png)               | 粵語聲母kw這個音叫做圓唇音，發這個音的舌位與發k相同，只不過把嘴唇收圓，近似發普通話裏 "誇kua" 裏 "ku" 的部分。       |

## 韻母

粵語的韻母有以下特點

1. 沒有韻頭（介音）。
2. 韻腹由 aa、a、o、oe、eo、e、u、yu、i 等元音組成。
3. 單韻母有 8 個：aa、a、o、oe、e、u、yu、i。
4. 複韻母有 11 個：即收 -i 或 -u 韻尾的韻母。當中 eoi 的 -i 受圓唇音 eo 影響，實際發出來的是圓唇音。
5. 鼻音韻母有 20 個：即收 -m、-n、-ng 韻尾的韻母。當中收 -m韻尾的韻母，發音時最後要把嘴巴合攏，如「添（tim1）」字的粵語發音，就像英語的 "Tim"。
6. 塞音韻母有 21 個：即收 -p、-t、-k 韻尾的韻母，也就是傳統所指的入聲。這類韻尾的發音跟英語有點相似，如「攝（sip3）」、「泄（sit3）」、「識（sik1）」三字的粵語發音， 就分別類近英語的 "sip"、"sit" 和 "sick"。不過，英語的 -p、-t、-k 韻尾，發音時氣流受阻之後會爆破成聲，而粵語的 -p、-t、-k 韻尾，只有閉塞而沒有爆破。另外要注意，收 -p 韻尾的韻母， 發音時最後要把嘴巴合攏。
7. 韻母 a 有長短之分，較長的用「aa」，較短的則用「a」來表示，例如「街（gaai1）」和「雞（gai1）」。
8. 粵語有 2 個圓唇韻母，分別是長元音 oe 和短元音 eo。要掌握oe，可以先試讀「靴（hoe1）」字，這個字的粵語發音類似英語的 "her"，但不用捲舌，而且要帶圓唇。至於 eo，其發音與 oe 相似，只是開口度較小，音長也較短。
9. 粵語有 2 個鼻音，分別是 m 和 嗯，可單獨成韻，例如「唔（m4）」和「五（ng5）」。



![韻母](韻母.png)

## 聲調

傳統的漢語聲調以平、上、去、入及陰陽來劃分，把粵語分成9個聲調。入聲分爲上陰入、下陰入、陽入三個聲調，但按音高來看，上陰入跟陰平、下陰入跟陰去、陽入跟陽去相同。香港語言學學會「粵語拼音方案」按實際音高來分，入聲不標，所以只標 6 聲。爲了讓同學更容易掌握聲調的調値及符號，現列表如下：


| 聲調  | 第一聲    | 第二聲 | 第三聲    | 第四聲 | 第五聲 | 第六聲   |
| --- | ------ | --- | ------ | --- | --- | ----- |
| 符號  | 1      | 2   | 3      | 4   | 5   | 6     |
| 調值  | 5 5    | 3 5 | 3 3    | 2 1 | 1 3 | 2 2   |
| 調類  | 陰平，上陰入 | 陰上  | 陰去，下陰入 | 陽平  | 陽上  | 陽去，陽入 |
]]></content>
      <tags>
        <tag>粤语</tag>
        <tag>语言</tag>
      </tags>
  </entry>
  <entry>
    <title>无线传输技术</title>
    <url>/2023/06/24/wireless-network-basic/</url>
    <content><![CDATA[
# 无线传输媒体

- 导向的
- 非导向的

## 常用频段

- 1GHz - 100GHz，微波，可用于点对点传输以及卫星通信
- 30MHz - 1GHz，无线电广播
- $3\times10^{11}$Hz - $2\times10^{14}$Hz，红外，本地应用

## 衰减

微波传输衰减公式

$$L=10\lg{\left(\frac{4\pi d}{\lambda}\right)^2}$$

# 天线

## 类型

- 偶极天线
- 抛物反射天线

## 天线增益

天线增益和有效面积之间的关系

$$G=\frac{4\pi A_e}{\lambda^2}=\frac{4\pi f^2A_e}{c^2}$$

- $G$ 为天线的增益
- $A_e$ 为天线的有效面积
- $f$ 为载波频率
- $c$ 为光速
- $\lambda$ 为载波波长

# 传播方式

- 天波传播（<2MHz）
- 地波传播（2-30MHz）
- 直线传播（>30MHz）

# 传输损耗

- 衰减和衰减失真
- 自由空间损耗
- 噪声
  - 热噪声
  - 互调噪声
  - 串扰
  - 脉冲噪声
- 大气吸收
- 多径
- 折射

# 移动环境中的衰退

衰退类型

- 平面/非选择性衰退
- 选择性衰退

差错补偿

- 前向纠错
- 适应性均衡
- 分集技术


# 多普勒效应

在无线电通信中，多普勒效应是指由于移动设备（如移动电话、无人机、雷达等）和基站之间的相对运动而导致信号频率发生变化的现象。这种变化可能会对通信系统的性能和可靠性产生影响，因此需要考虑和处理多普勒效应。

当移动设备和基站之间相对运动时，根据多普勒效应的原理，信号的频率会发生变化。具体而言，如果移动设备向基站靠近，观测者（基站）会感知到信号频率变高，称为正多普勒效应。相反，如果移动设备远离基站，观测者会感知到信号频率变低，称为负多普勒效应。

在无线电通信系统中，多普勒效应的处理是至关重要的，特别是对于高速移动设备或基站的情况。以下是一些常见的处理多普勒效应的方法：

1. 频率补偿
   基站可以根据移动设备和基站之间的相对速度，对接收到的信号频率进行补偿。通过测量相对速度并应用适当的频率偏移，可以消除多普勒效应引起的频率偏差，从而保持通信的可靠性。

2. 盲速估计和补偿
   在某些情况下，移动设备可能无法直接提供其运动信息。此时，基站可以使用盲速估计算法来估计移动设备的相对速度，并相应地对接收到的信号进行频率补偿。

3. 多天线技术
   多天线技术（如天线阵列）可以通过空间分集和波束成形的方法减轻多普勒效应的影响。通过多路径传播的信号可以从多个方向接收，并在接收端进行合并处理，以降低多普勒效应带来的干扰。

4. 自适应调制
   自适应调制技术可以根据信道条件的变化，自动调整调制方式和参数。通过根据多普勒效应的影响来选择适当的调制方式，可以提高信号的可靠性和传输效率。

# 扩频

扩频技术（Spread Spectrum）是一种在无线通信中广泛应用的技术，它通过将信号在更宽的频带上进行传输，以提高通信的可靠性、抗干扰性和安全性。

## 原理

扩频技术基于信号的频谱扩展原理，通过将原始信号与一个宽带的扩频码进行数学运算，使信号在更大的频带范围内传输。这个扩频码可以是一个伪随机序列，也称为扩频序列或码片。

## 扩频序列

扩频序列是一串伪随机的二进制码片序列，其特点是具有较好的互相关性。发送端使用扩频序列将原始数据进行编码，接收端使用相同的扩频序列进行解码，以还原出原始数据。常用的扩频序列包括加法扩频码（例如 N 序列）和乘法扩频码（例如 Gold 码）。

## 扩频方式

- 直接序列扩频（Direct Sequence Spread Spectrum，DSSS）：发送端将原始信号与扩频码进行逐位的直接相乘，从而实现频谱的扩展。接收端通过与发送端使用相同的扩频码进行相关运算，将扩展的信号还原为原始信号。
- 跳频扩频（Frequency Hopping Spread Spectrum，FHSS）：发送端在一个较宽的频带内划分多个子信道，并按照一定的规律，周期性地在这些子信道之间进行切换。接收端需要与发送端保持同步，并按照相同的规律进行频道的切换，以恢复原始信号。
- 跳时扩频（Time Hopping Spread Spectrum，THSS）基于时间域上的扩频原理，在信号传输过程中，将原始信号分割成短时隙，并根据扩频码的规则进行时隙的跳跃。在每个时隙中，信号以窄带方式传输，并在不同的时隙中通过改变扩频码进行频谱扩展。
- 脉冲调频。使用调频脉冲进行数据传输，扩频函数控制调频模式。
- 混合扩频。

## 优点

- 抗干扰性：扩频技术可以有效抵抗窄带干扰，因为干扰信号只会在整个频带范围内被均匀分布，而且接收端只有在正确的扩频序列下才能还原出原始信号。
- 安全性：由于扩频码是伪随机的，只有知道正确的扩频序列的接收端才能正确解码，从而实现了一定的安全性。
- 高可靠性：由于信号在更宽的频带上传输，扩频技术对信道衰落和多径效应具有较好的容忍性，提供了更可靠的通信连接。

扩频技术在许多应用中得到广泛应用，包括无线局域网（WLAN）、蓝牙、CDMA 手机通信等。通过扩展信号的频谱，扩频技术提高了通信系统的性能和可靠性，使得无线通信更加稳定和安全。

# 差错控制

## 差错检测码

差错检测码（Error Detection Code）是一种用于检测数据传输过程中错误的编码技术。它通过在数据中添加冗余位（校验位）来帮助接收方检测传输过程中可能发生的错误。差错检测码广泛应用于计算机网络、通信系统和存储介质等领域，以确保数据的可靠性和完整性。

1. 奇偶校验（Parity Check）
   奇偶校验是一种基本的差错检测码。在奇偶校验中，发送方在数据中添加一个奇偶位，使得数据中 1 的个数为奇数（奇校验）或偶数（偶校验）。接收方在接收数据后重新计算奇偶位，并与接收到的校验位进行比较，以检测错误。奇偶校验可以检测到单比特错误，但无法纠正错误。

2. 循环冗余检验（Cyclic Redundancy Check，CRC）
   CRC 是一种常见的差错检测码，也可以用于纠正错误。CRC 通过除法运算将数据进行多项式编码，并将编码后的冗余校验码添加到数据中。接收方通过再次进行多项式除法运算，并检查接收到的冗余校验码是否匹配，以确定是否有错误发生。CRC 可以检测和纠正多比特错误。

3. 奇偶纠错码（BCH Code）
   奇偶纠错码是一种用于检测和纠正多比特错误的差错检测码。它在数据中添加冗余位，并使用数学算法来检测和纠正错误。奇偶纠错码可以根据不同的需求和纠错能力进行选择。

4. 校验和（Checksum）
   校验和是一种简单的差错检测码，常用于网络传输中。发送方将数据分成较小的块，对每个块计算校验和，并将校验和添加到数据中。接收方在接收到数据后，再次计算校验和，并与接收到的校验和进行比较。如果校验和不匹配，则认为数据存在错误。

差错检测码在数据传输过程中起着重要的作用，可以帮助接收方检测传输中的错误。通过选择适当的差错检测码，可以提高数据传输的可靠性，并及时发现和处理错误。

## 差错纠错码

差错纠错码（Error Correction Code）是一种用于检测和纠正数据传输中的错误的编码技术。与差错检测码只能检测错误不同，差错纠错码能够在一定范围内检测错误并纠正它们，从而提高数据的可靠性和完整性。

1. 海明码（Hamming Code）
   海明码是一种常用的差错纠错码。它通过在数据中添加冗余位（校验位）来纠正错误。海明码使用特定的编码规则，在数据中插入校验位，使得校验位与数据中的比特按照一定规则进行排列。接收方通过比较接收到的数据和校验位，可以检测并纠正单比特错误。海明码可以纠正单比特错误，并检测多比特错误。

2. 重复编码
   重复编码是一种简单的差错纠错码方法。发送方将每个比特重复发送多次，接收方通过多次接收并比较来检测和纠正错误。例如，将每个比特发送三次，如果接收到的比特中有两个或三个相同，则接收方将判断为正确。重复编码可以纠正少量的比特错误，但会增加传输的开销。

3. BCH 码（Bose-Chaudhuri-Hocquenghem Code）
   BCH 码是一类常见的差错纠错码，用于纠正多比特错误。BCH 码根据所需的纠错能力和数据长度选择不同的参数。它利用数学算法将数据进行编码，并在接收方使用纠错算法对接收到的数据进行解码和纠正。BCH 码能够纠正多比特错误，具有较高的纠错能力。

4. RS 码（Reed-Solomon Code）
   RS 码是一种常用的差错纠错码，被广泛应用于数据存储和通信系统中。RS 码使用多项式运算来进行编码和解码，具有强大的纠错能力。它可以纠正多比特错误，包括突发错误和随机错误。

差错纠错码通过添加冗余位和利用纠错算法来提供数据纠正能力。它们在数据通信中起着重要的作用，可以检测和纠正传输过程中的错误，提高数据的可靠性和完整性。选择适当的差错纠错码取决于纠错能力要求和系统的特定需求。

## ARQ

自动重发请求（Automatic Repeat Request，ARQ）是一种差错控制技术，用于在计算机网络中检测和纠正数据传输中的错误。ARQ 通过发送方发送数据包并等待接收方的确认（ACK）来实现错误检测和纠正。

1. 发送方工作流程：

   - 发送数据：发送方将数据分成较小的数据包，并通过网络发送给接收方。
   - 等待确认：发送方等待接收方发送确认（ACK）信号，表示数据包已正确接收。
   - 超时重发：如果发送方在一定时间内未收到确认信号，即发生超时，发送方会假设数据包丢失或损坏，并重新发送相同的数据包。

2. 接收方工作流程：

   - 接收数据：接收方接收发送方发送的数据包。
   - 校验数据：接收方对接收到的数据包进行校验，以检测是否有错误发生。
   - 发送确认：如果数据包没有错误，接收方发送确认信号（ACK）给发送方。
   - 检测和丢弃重复数据包：接收方检测重复的数据包，并将其丢弃，以防止重复处理。

3. ARQ 的重发机制：

   - 确认丢失：如果发送方发送了数据包但未收到确认信号，发送方假设数据包丢失，并重新发送相同的数据包。
   - 错误检测：接收方在校验数据包时发现错误，将不发送确认信号，以指示发送方需要重新发送数据包。
   - 超时重发：发送方设置一个超时定时器，如果在规定的时间内未收到确认信号，则认为数据包丢失，并重新发送数据包。

ARQ 的优点是能够在数据传输过程中检测和纠正错误，提高了数据的可靠性。然而，ARQ 的缺点是增加了网络的延迟和带宽开销，因为需要重复发送数据包和等待确认信号。

在 ARQ 中，还存在多种变体，如停止等待 ARQ 和连续 ARQ。停止等待 ARQ 是一种简单的 ARQ 方法，发送方在发送数据包后，等待接收到确认信号后才发送下一个数据包。连续 ARQ 是一种更高效的 ARQ 方法，允许发送方连续发送多个数据包，而无需等待每个数据包的确认信号。]]></content>
      <tags>
        <tag>Wireless-Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Wireless Network Conclusion</title>
    <url>/2023/06/25/wireless-network-conclusion/</url>
    <content><![CDATA[
# 英文缩写

- WAN, Wide Area Network
- LAN, Local Area Network
- WWAN, Wireless Wide Area Network
- WPAN, Wireless Personal Area Network
- WSN, Wireless Sensor Network
- WMN, Wireless Mesh Network
- IEEE, the Institute of Electrical and Electronics Engineers, 电气电子工程师学会
- ITU, International Telecommunication Union, 国际电信联盟
- ISO, International Standards Organization
- IETF, Internet Engineering Task Force, Internet 工程任务组
- IAB, Internet Architecture Board, Internet 体系结构委员会
- IRTF, Internet Research Task Force, Internet 研究任务组
- ANSI, American National Standards Institute, 美国国家标准协会
- 3GPP, The 3rd Generation Partnership Project
- IPDR, The Internet Protocol Detail Record
- CDMA, Code Division Multiple Access, 码分多路复用
- ETSI, European Telecommunications Standards Institute
- Wi-Fi, Wireless Fidelity
- BSS, Basic Service Set
- IBSS, Independent Basic Service Set
- AP, Access Point
- ESS, Extended Service Set
- IESS, Independent Extended Service Set
- DHCP, Dynamic Host Configuration Protocol
- WAPI, Wireless LAN Authentication and Privacy Infrastructure, 无线局域网鉴别和保密基础结构
- WEP, Wire Equivalent Privacy, 有线等效加密

# 名词

- 无线穿戴网，基于短距离无线通信技术与可穿戴式计算机技术，穿戴在人体上具有智能收集人体和周围环境信息的一种新型个域网
- 无线体域网 BAN，是由依附于身体的各种传感器构成的网络
- OSI RM
  - 物理层
  - 数据链路层
  - 网络层
  - 传输层
  - 会话层
  - 表示层
  - 应用层
- 微波，频率在 300MHz - 300GHz 之间的电磁波
- 天线，实现无线传输最基本的设备，可以看做为一条电子导线或导线系统，该导线系统或用于将电磁能辐射到太空，或用于将太空中的电磁能收集起来
- 天线增益，天线定向性的度量，与有理论的全向天线在各个方向所产生的输出相比，天线增益定义为在一特定方向上的功率输出
- 衰减，信号的强度随着跨越的传输媒介的距离而降低
- 自由空间损耗，信号会随着距离发散，具有固定面积的天线离发射天线越远，接收的信号功率越低

# 部分知识点

## 无线网络的分类（应用）

- 无线传感器网络
- 无线 Mesh 网络
- 无线穿戴网络
- 无线体域网络

## 无线网络的协议模型特点

- 基于分层体系结构
- 不关注路由问题，没有网络层的协议，采用传统的 IP
- 存在共享访问介质的问题，因此 MAC 协议是无线网络协议的重点

## ISM 频段

- 902MHz~928MHz
- 2.4GHz~2.4835GHz
- 5.735GHz~5.860GHz

## 直线传输系统中的损伤

- 衰减和衰减失真
- 自由空间损耗
- 噪声
- 大气吸收
- 多径
- 折射

## 不同 IFS 的作用

- SIFS，用于所有立即响应的动作
- PIFS，在发布轮询时，被中央控制器用于 PCF 模式
- DIFS，非同步侦的接入竞争

## WLAN 的拓扑结构

- 分布对等式拓扑
- 基础结构集中式拓扑
- ESS 网络拓扑
- 中继或桥接型网络拓扑

## WLAN 的服务

- STA 服务（SS）
  - 认证
  - 解除认证
  - 保密
  - MAC 服务数据单元传送
- 分布式系统服务（DSS）
  - 联结
  - 重新联结
  - 解除联结
  - 分布
  - 集成

## 无线 Mesh 网络与蜂窝网络的主要区别

- 可靠性提高，自愈性强
- 传输速率大大提高
- 投资成本降低
- 网络配置和维护简便快捷

## 无线 Mesh 网络与 WLAN 的主要区别

- 从拓扑结构上看，WLAN 是典型的点对多点（P2MP，Point to Multiple Points）网络，而且采取单跳方式，因而数据不可转发。WMN 可以通过 WR 对数据进行智能转发（需要对 WLAN 传统的 AP 功能进行扩展和改进）。
- 从协议上看，WMN 与移动 Ad Hoc 网络基本类似。WLAN 的 MAC 协议完成的是本地业务的接入，而 WMN 则有两种可能，一种是本地业务的接入，另一种是其他节点业务的转发。对于路由协议，WLAN 是静态的因特网路由协议和移动 IP；但 WMN 则主要是动态的按需发现的路由协议，只具有较短暂的生命周期。

## 无线 Mesh 网络与 Ad Hoc 的主要区别

- WMN 由无线路由器构成的无线骨干网组成。该无线骨干网提供了大范围的信号覆盖与节点连接。移动 Ad Hoc 网络的节点都兼有独立路由和主机功能，节点地位平等，接通性是依赖端节点的平等合作实现的，健壮性比 WMN 差。
- WMN 节点移动性低于移动 Ad Hoc 网络中的节点，所以 WMN 注重的是“无线”，而移动 Ad Hoc 网络更强调的是“移动”。
- 从网络结构来看，WMN 多为静态或弱移动的拓扑，而移动 Ad Hoc 网络多为随意移动(包括高速移动)的网络拓扑。
- WMN 与移动 Ad Hoc 网络的业务模式不同，前者节点的主要业务是来往于因特网的业务，后者节点的主要业务是任意一对节点之间的业务流。
- 从应用来看，WMN 主要是因特网或宽带多媒体通信业务的接入，而移动 Ad Hoc 网络主要用于军事或其他专业通信。

## WMN 的优缺点

- 优点
  - 可靠性大大增强
  - 具有冲突保护机制
  - 简化链路设计
  - 网络的覆盖范围增大
  - 组网灵活、维护方便
  - 投资成本低、风险小
- 缺点
  - 对于不同射频信道的 WMN 的研究还处于试验研制阶段，性能改善总体来说还不太满
  - 在 WMN 路由准则和选择算法等方面，目前提出的特别适用于 WMN 的路由协议寥寥无几
  - 在 WMN 连接性和多路支持方面，每个节点链路连接度也是一个至关重要的问题，并非使用射频信道数越多，网络性能越好，射频信道数增加会带来设备开销和成本上升，同时可能会带来更多的干扰问题
  - 在 WMN 带宽利用和资源分配算法方面，目前还没有提出非常有效的可用算法和协议，相关问题还有待研究

# 计算

## 信道容量

在信号平均功率有限的⽩噪声（指通信系统内部本身产⽣的噪声）信道中，信道的极限数据传输率（即信道容量）为

$$C=W\log_2(1+\frac{S}{N})\;bps$$

- $S$ 表示信号功率
- $N$ 表示噪声功率
- $W$ 为信道带宽
- $C$ 为信道容量

## Nyquist 准则

离散⽆噪声的数字信道信道容量为

$$C=2W\log_2L$$

- $W$ 为信道的带宽（Hz）
- $L$ 为代码采⽤的进制数
]]></content>
      <tags>
        <tag>Wireless-Network</tag>
      </tags>
  </entry>
  <entry>
    <title>WLAN</title>
    <url>/2023/06/24/wireless-network-wlan/</url>
    <content><![CDATA[
# 组成

- 站 Station, STA
  - 终端用户设备
  - 无线网络接口
  - 网络软件
- 无线介质 Wireless Medium, VM
- 基站/接入点 Base Station, BS / Access Point, AP
- 分布式系统 Distribution System, DS

# 拓扑结构

- 分布对等式拓扑
- 基础结构集中式拓扑
- ESS 网络拓扑
- 中继或桥接型网络拓扑

# 服务

- STA 服务 SS
- 分布式系统服务 DSS
]]></content>
      <tags>
        <tag>Wireless-Network</tag>
      </tags>
  </entry>
  <entry>
    <title>每日幾句</title>
    <url>/2024/03/27/%E6%AF%8F%E6%97%A5%E5%B9%BE%E5%8F%A5/</url>
    <content><![CDATA[- **三月二十七日，週三**
	- nei5 hou2 aa1，gam1 jat6 jau6 mou5 soeng2 ngo5。
	- 你好啊，今日又冇想我。 
	- m4 zi1 dou6 soeng2 jiu3 sik6 mat1 je5。
	- 唔知道想要食乜嘢。
]]></content>
      <tags>
        <tag>粤语</tag>
        <tag>语言</tag>
      </tags>
  </entry>
  <entry>
    <title>&#39;tag&#39;</title>
    <url>/tag/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
</search>
